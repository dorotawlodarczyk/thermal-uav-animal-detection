{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6eba163-6c7c-4c36-a347-9a491e659077",
   "metadata": {},
   "source": [
    "## Feature Extraction: CNN + Geometric & Temperature Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configuration for GitHub or local use\n",
    "import os\n",
    "\n",
    "# Main project folder\n",
    "BASE_PATH = \"./data/\"\n",
    "\n",
    "# Folder containing thermal images (CREATE THIS FOLDER MANUALLY)\n",
    "# It is recommended to name the images based on the timestamp of the recording or the order in which the images are taken. \n",
    "# The format should follow HH-MM-SS (Hour-Minute-Second), e.g., 00-01-01.\n",
    "IMAGE_PATH = os.path.join(BASE_PATH, \"thermal_images/\")\n",
    "\n",
    "# --- FOLDERS AUTOMATICALLY CREATED IN BASE_PATH ---\n",
    "\n",
    "# Folder for saving the CNN model\n",
    "CNN_MODEL = os.path.join(BASE_PATH, \"cnn_model/\")\n",
    "\n",
    "# Folder for saving CNN feature maps (activations)\n",
    "ACTIVATION_PATH = os.path.join(BASE_PATH, \"cnn_activations/\")\n",
    "\n",
    "# Folder for saving segment features: CNN cutouts, CSV with thermal and geometric features\n",
    "RESULT_FEATURES = os.path.join(BASE_PATH, \"result_features/\")\n",
    "\n",
    "# Ensure folders exist\n",
    "for path in [BASE_PATH, ACTIVATION_PATH, IMAGE_PATH, RESULT_FEATURES, CNN_MODEL]:\n",
    "    os.makedirs(path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a2989-5505-4c31-8ae4-89137f36a82c",
   "metadata": {},
   "source": [
    "### 1. Build CNN Model for Multi-Scale Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefd915-171f-4231-be48-648f5f2f2a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Flatten, concatenate\n",
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Model configuration\n",
    "activation = 'sigmoid'\n",
    "optimizer = 'rmsprop'\n",
    "\n",
    "# Input shape: height, width, channels\n",
    "input_layer = Input(shape=(288, 382, 1))\n",
    "\n",
    "# Parallel convolutional layers with different kernel sizes\n",
    "conv1 = Conv2D(16, (2, 2), activation=activation, padding='same')(input_layer)\n",
    "norm1 = BatchNormalization()(conv1)\n",
    "\n",
    "conv2 = Conv2D(16, (3, 3), activation=activation, padding='same')(input_layer)\n",
    "norm2 = BatchNormalization()(conv2)\n",
    "\n",
    "conv3 = Conv2D(8, (5, 5), activation=activation, padding='same')(input_layer)\n",
    "norm3 = BatchNormalization()(conv3)\n",
    "\n",
    "conv4 = Conv2D(8, (7, 7), activation=activation, padding='same')(input_layer)\n",
    "norm4 = BatchNormalization()(conv4)\n",
    "\n",
    "# Concatenate and flatten the feature maps\n",
    "concatenated = concatenate([norm1, norm2, norm3, norm4])\n",
    "flat = Flatten()(concatenated)\n",
    "\n",
    "# Define and compile the model\n",
    "model = Model(inputs=input_layer, outputs=flat)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "# Display model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Save the model in TensorFlow .keras format\n",
    "model_save_path = os.path.join(CNN_MODEL, \"cnn_model.keras\")\n",
    "\n",
    "try:\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved in TensorFlow format at: {model_save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError while saving the model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7bf048-c37f-4295-a78b-bfaf96c6b122",
   "metadata": {},
   "source": [
    "### 2. Process Input Images Using Pretrained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b74ac-c04e-4ea5-af1f-f76e76e1a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import warnings\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_path = os.path.join(CNN_MODEL, \"cnn_model.keras\")\n",
    "\n",
    "# Load all TIFF images\n",
    "image_files = glob(os.path.join(IMAGE_PATH, \"*.tiff\"))\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(file_path):\n",
    "    img = rioxarray.open_rasterio(file_path)\n",
    "    img = img[0].values\n",
    "    img = cv2.resize(img, (382, 288))\n",
    "    img = img.astype('float32')\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Load pre-trained CNN model and define intermediate layer outputs\n",
    "model = load_model(model_path)\n",
    "activation_model = Model(inputs=model.input, outputs=[layer.output for layer in model.layers if 'conv' in layer.name])\n",
    "\n",
    "# Initialize batching parameters\n",
    "batch_size = 500\n",
    "batch_counter = 0\n",
    "image_counter = 0\n",
    "all_activations = [[] for _ in range(len(activation_model.output))]\n",
    "\n",
    "# Save mapping of processed images\n",
    "mapping_file_path = os.path.join(ACTIVATION_PATH, 'image_mapping.txt')\n",
    "\n",
    "with open(mapping_file_path, 'w') as f:\n",
    "    f.write('img_path,img_name\\n')\n",
    "\n",
    "    # Process each image and extract activations\n",
    "    for file in image_files:\n",
    "        img = preprocess_image(file)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        activations = activation_model.predict(img, verbose=0)\n",
    "\n",
    "        # Save image metadata\n",
    "        image_name = os.path.basename(file)\n",
    "        f.write(f\"{file},{image_name}\\n\")\n",
    "\n",
    "        # Store layer activations\n",
    "        for i, activation in enumerate(activations):\n",
    "            all_activations[i].append(activation)\n",
    "\n",
    "        image_counter += 1\n",
    "\n",
    "        # Save batched activations\n",
    "        if image_counter >= batch_size:\n",
    "            for i, activations in enumerate(all_activations):\n",
    "                activations = np.concatenate(activations, axis=0)\n",
    "                activation_path = os.path.join(ACTIVATION_PATH, f\"activations_layer_{i+1}_batch_{batch_counter+1}.npy\")\n",
    "                np.save(activation_path, activations)\n",
    "\n",
    "            all_activations = [[] for _ in range(len(activation_model.output))]\n",
    "            image_counter = 0\n",
    "            batch_counter += 1\n",
    "            gc.collect()\n",
    "\n",
    "# Save remaining images (if any)\n",
    "if image_counter > 0:\n",
    "    for i, activations in enumerate(all_activations):\n",
    "        activations = np.concatenate(activations, axis=0)\n",
    "        activation_path = os.path.join(ACTIVATION_PATH, f\"activations_layer_{i+1}_batch_{batch_counter+1}.npy\")\n",
    "        np.save(activation_path, activations)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time [min]: {(end_time - start_time)/60:.2f}\")\n",
    "\n",
    "print(f\"Activations and image mapping saved successfully at: {ACTIVATION_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72692e-14fe-45c0-b123-cdc7123eecae",
   "metadata": {},
   "source": [
    "### 3. Batch Merging for Feature Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c864867-d0b3-49af-9dec-c1d77efde7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "\n",
    "# Loop through all desired activation layers\n",
    "for nr in [1, 2, 3, 4]:\n",
    "    print(f\"\\n--- Processing layer {nr} ---\")\n",
    "\n",
    "    # Find all batch files for the current layer\n",
    "    layer_files = sorted(glob(os.path.join(ACTIVATION_PATH, f\"activations_layer_{nr}_batch_*.npy\")))\n",
    "    if not layer_files:\n",
    "        print(f\"No batch files found for layer {nr}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    all_activations = []\n",
    "\n",
    "    # Load and accumulate activations\n",
    "    for file in layer_files:\n",
    "        print(f\"Loading {file}\")\n",
    "        activations_batch = np.load(file)\n",
    "        all_activations.append(activations_batch)\n",
    "\n",
    "    # Concatenate all batches into one array\n",
    "    merged_activations = np.concatenate(all_activations, axis=0)\n",
    "\n",
    "    # Save the merged activations\n",
    "    output_file = os.path.join(ACTIVATION_PATH, f\"activations_layer_{nr}.npy\")\n",
    "    np.save(output_file, merged_activations)\n",
    "    print(f\"Merged activations saved to: {output_file}\")\n",
    "\n",
    "    # Release memory and file handles\n",
    "    del all_activations\n",
    "    gc.collect()\n",
    "\n",
    "    # Delete original batch files\n",
    "    for file in layer_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Deleted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf180c06-a42f-4d3d-a6a1-16976186f2ae",
   "metadata": {},
   "source": [
    "### 4. Segment Detection and Convolutional Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6442b-2f0f-42f6-acdc-1567bd17e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import gc\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "gc.collect()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "image_mapping_file = ACTIVATION_PATH + \"image_mapping.txt\"\n",
    "mapping_csv_file = RESULT_FEATURES + \"image_features_mapping.csv\"\n",
    "\n",
    "# Utility functions\n",
    "def contour_to_string(contour):\n",
    "    return json.dumps(contour.squeeze().tolist())\n",
    "\n",
    "def adjust_window_to_bounds(cx, cy, image_shape, window_size=30, min_margin=3):\n",
    "    x_start = cx - window_size // 2\n",
    "    y_start = cy - window_size // 2\n",
    "    x_end = x_start + window_size\n",
    "    y_end = y_start + window_size\n",
    "\n",
    "    if (x_start < min_margin or x_end > image_shape[1] - min_margin or\n",
    "        y_start < min_margin or y_end > image_shape[0] - min_margin):\n",
    "        return None\n",
    "    return x_start, y_start, x_end, y_end\n",
    "\n",
    "# Load image mapping\n",
    "image_mapping = {}\n",
    "with open(image_mapping_file, 'r') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        img_path, img_name = line.strip().split(',')\n",
    "        image_mapping[img_name] = img_path\n",
    "\n",
    "# Load activation files\n",
    "activation_files = glob(os.path.join(ACTIVATION_PATH, \"activations_layer_*.npy\"))\n",
    "\n",
    "# Parameters\n",
    "min_area = 1\n",
    "max_area = 50\n",
    "window_size = 30\n",
    "# Minimum RMS deviation (from median temperature) in DN required to accept a detected segment\n",
    "rms_treshold = 100 # thermal resolution of 100 DN per 1Â°C in 16-bit thermal image\n",
    "\n",
    "data_for_csv = []\n",
    "is_csv_saved = False\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each activation file (corresponding to a CNN layer)\n",
    "for activation_file in activation_files:\n",
    "    activations = np.load(activation_file, mmap_mode='r')\n",
    "    num_filters = activations.shape[-1]\n",
    "    layer_name = os.path.basename(activation_file).replace('.npy', '')\n",
    "    all_cutouts_for_layer = []\n",
    "\n",
    "    # Process each image in the current activation file\n",
    "    for img_idx in range(activations.shape[0]):\n",
    "        activation_map = activations[img_idx]\n",
    "\n",
    "        img_name = list(image_mapping.keys())[img_idx]\n",
    "        img_path = os.path.join(IMAGE_PATH, image_mapping[img_name])\n",
    "        original_image = rxr.open_rasterio(img_path).squeeze()\n",
    "        \n",
    "        # Normalize and smooth the image for thresholding\n",
    "        X = np.array(original_image, dtype=np.int16)\n",
    "        X_normalized = cv2.normalize(X, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        X_smoothed = gaussian_filter(X_normalized, sigma=0.95)\n",
    "\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(X_smoothed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                                cv2.THRESH_BINARY, 13, -8)\n",
    "        contours, _ = cv2.findContours(adaptive_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filter contours by area and select top 10 by temperature\n",
    "        filtered_contours = []\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if min_area < area < max_area:\n",
    "                mask_contour = np.zeros_like(X, dtype=np.int16)\n",
    "                cv2.drawContours(mask_contour, [cnt], -1, 1, thickness=cv2.FILLED)\n",
    "                masked_temps = np.ma.masked_array(X, mask=~(mask_contour.astype(bool)))\n",
    "                max_temp = masked_temps.max()\n",
    "                filtered_contours.append((cnt, max_temp, area))\n",
    "        filtered_contours = sorted(filtered_contours, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        coordinates = []\n",
    "\n",
    "        # Extract windowed cutouts from activation map\n",
    "        for cnt, max_temp, original_area in filtered_contours:\n",
    "            M = cv2.moments(cnt)\n",
    "            if M['m00'] != 0:\n",
    "                cx = int(M['m10'] / M['m00'])\n",
    "                cy = int(M['m01'] / M['m00'])\n",
    "                cnt_str = contour_to_string(cnt)\n",
    "\n",
    "                result = adjust_window_to_bounds(cx, cy, activation_map.shape, window_size, min_margin=4)\n",
    "                if result is not None:\n",
    "                    x_start, y_start, x_end, y_end = result\n",
    "\n",
    "                    # Compute root mean square of temperature deviations from the median (robust measure of variability)\n",
    "                    mask_contour = np.zeros_like(X, dtype=np.uint16)\n",
    "                    cv2.drawContours(mask_contour, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "                    masked_temps = np.ma.masked_array(X, mask=~(mask_contour.astype(bool)))\n",
    "\n",
    "                    median_temp = np.ma.median(masked_temps)\n",
    "                    std_temp = masked_temps.std()\n",
    "                    rms_from_median = np.sqrt(np.mean((masked_temps - median_temp) ** 2))\n",
    "\n",
    "                    if rms_from_median >= rms_treshold:\n",
    "                        cropped_image = activation_map[y_start:y_end, x_start:x_end, :]\n",
    "                        all_cutouts_for_layer.append(cropped_image)\n",
    "                        coordinates.append([img_path, img_name, cx, cy, cnt_str])\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        if not is_csv_saved:\n",
    "            data_for_csv.extend(coordinates)\n",
    "\n",
    "    # Save cropped cutouts for the current layer\n",
    "    if all_cutouts_for_layer:\n",
    "        all_cutouts_array = np.array(all_cutouts_for_layer)\n",
    "        cutout_save_path = os.path.join(RESULT_FEATURES, f\"{layer_name}_cutouts.npy\")\n",
    "        np.save(cutout_save_path, all_cutouts_array)\n",
    "        print(f\"{layer_name} - shape: {all_cutouts_array.shape}\")\n",
    "\n",
    "    # Save CSV with contour mapping\n",
    "    if not is_csv_saved:\n",
    "        df = pd.DataFrame(data_for_csv, columns=['img_path', 'img_name', 'cx', 'cy', 'contour'])\n",
    "        df.to_csv(mapping_csv_file, index=False)\n",
    "        is_csv_saved = True\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time [min]: {(end_time - start_time)/60:.2f}\")\n",
    "\n",
    "print(f\"Saved to: {RESULT_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425802b-bd84-48f5-a9ab-f8fef444352c",
   "metadata": {},
   "source": [
    "### 5. Geometric and Temperature Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c3c38-d47e-43f7-bca0-400f73a77711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import rioxarray\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paths\n",
    "mapping_csv_file = RESULT_FEATURES + \"image_features_mapping.csv\"\n",
    "\n",
    "# Utility functions for contour serialization\n",
    "def string_to_contour(contour_string):\n",
    "    return np.array(json.loads(contour_string), dtype=np.int32).reshape(-1, 1, 2)\n",
    "\n",
    "def contour_to_string(contour):\n",
    "    return json.dumps(contour.squeeze().tolist())\n",
    "\n",
    "# Fit PCA to extract ellipse parameters\n",
    "def fit_ellipse_pca(points, scale_factor=1.0):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(points)\n",
    "    center = pca.mean_\n",
    "    axes = np.sqrt(pca.explained_variance_) * 2 * scale_factor\n",
    "    angle = np.degrees(np.arctan2(pca.components_[0, 0], pca.components_[0, 1]))\n",
    "    projections = pca.transform(points)\n",
    "    return center, axes, angle, projections\n",
    "\n",
    "# Generate points within a specified radius\n",
    "def generate_points_in_radius(center, radius):\n",
    "    points_in_radius = []\n",
    "    cy, cx = center\n",
    "    for y in range(int(cy - radius), int(cy + radius) + 1):\n",
    "        for x in range(int(cx - radius), int(cx + radius) + 1):\n",
    "            if np.sqrt((x - cx)**2 + (y - cy)**2) <= radius:\n",
    "                points_in_radius.append((y, x))\n",
    "    return np.array(points_in_radius)\n",
    "    \n",
    "# Check if a point lies inside an ellipse\n",
    "def is_point_in_ellipse(y, x, center, axes, angle, margin=0.2):\n",
    "    cy, cx = center\n",
    "    a, b = axes[0], axes[1]\n",
    "    angle_rad = np.radians(angle)\n",
    "    cos_angle = np.cos(angle_rad)\n",
    "    sin_angle = np.sin(angle_rad)\n",
    "    x_shifted = x - cx\n",
    "    y_shifted = y - cy\n",
    "    x_rot = cos_angle * x_shifted + sin_angle * y_shifted\n",
    "    y_rot = -sin_angle * x_shifted + cos_angle * y_shifted\n",
    "    return (x_rot**2) / (a**2) + (y_rot**2) / (b**2) <= 1 + margin\n",
    "\n",
    "# Calculate ellipse circumference (Ramanujan approximation)\n",
    "def calculate_ellipse_circumference(axes):\n",
    "    a, b = axes\n",
    "    return np.pi * (3*(a + b) - np.sqrt((3*a + b)*(a + 3*b)))\n",
    "\n",
    "# Calculate ellipse area\n",
    "def calculate_ellipse_area(axes):\n",
    "    a, b = axes\n",
    "    return np.pi * a * b\n",
    "\n",
    "# Main feature extraction loop\n",
    "def main_process(mapping_csv_file):\n",
    "    df = pd.read_csv(mapping_csv_file)\n",
    "    df['contour'] = df['contour'].apply(string_to_contour)\n",
    "    neighborhood_features = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        image_path = row['img_path']\n",
    "        img_name = row['img_name']\n",
    "        contour = row['contour']\n",
    "        cx = row['cx']\n",
    "        cy = row['cy']\n",
    "\n",
    "        image = rioxarray.open_rasterio(image_path)\n",
    "        X = np.array(image[0], dtype=np.int16)\n",
    "\n",
    "        # Create binary mask from contour\n",
    "        mask_contour = np.zeros_like(X, dtype=np.uint16)\n",
    "        cv2.drawContours(mask_contour, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "        points = np.column_stack(np.where(mask_contour == 255))\n",
    "\n",
    "        if len(points) > 3:\n",
    "            center, axes, angle, projections = fit_ellipse_pca(points)\n",
    "\n",
    "            # Define elliptical neighborhood\n",
    "            radius = 15 # half of the window size in pixels  \n",
    "            points_in_radius = generate_points_in_radius(center, radius)\n",
    "            inside_ellipse_mask = np.array([is_point_in_ellipse(y, x, center, axes, angle) for (y, x) in points_in_radius])\n",
    "            points_inside_actual_ellipse = points_in_radius[inside_ellipse_mask]\n",
    "            points_inside_actual_ellipse = np.clip(points_inside_actual_ellipse, 0, np.array(X.shape) - 1)\n",
    "\n",
    "            # Define scaled ellipse (150% size)\n",
    "            scaled_axes = axes * 1.5\n",
    "            inside_scaled_ellipse_mask = np.array([is_point_in_ellipse(y, x, center, scaled_axes, angle) for (y, x) in points_in_radius])\n",
    "            points_remaining = points_in_radius[inside_scaled_ellipse_mask & ~inside_ellipse_mask]\n",
    "            points_remaining = np.clip(points_remaining, 0, np.array(X.shape) - 1)\n",
    "\n",
    "            # Temperature statistics\n",
    "            temperatures_inside_ellipse = X[points_inside_actual_ellipse[:, 0], points_inside_actual_ellipse[:, 1]]\n",
    "            temperatures_remaining = X[points_remaining[:, 0], points_remaining[:, 1]]\n",
    "\n",
    "            max_temp_ellipse = np.max(temperatures_inside_ellipse)\n",
    "            min_temp_ellipse = np.min(temperatures_inside_ellipse)\n",
    "            max_temp_remaining = np.max(temperatures_remaining)\n",
    "            min_temp_remaining = np.min(temperatures_remaining)\n",
    "\n",
    "            max_temp_diff = max_temp_ellipse - max_temp_remaining\n",
    "            min_temp_diff = min_temp_ellipse - min_temp_remaining\n",
    "            remaining_temp_range = max_temp_remaining - min_temp_remaining\n",
    "            ellipse_temp_range = max_temp_ellipse - min_temp_ellipse\n",
    "\n",
    "            # PCA and geometric features\n",
    "            std_pca_component_1 = projections[:, 0].std()\n",
    "            std_pca_component_2 = projections[:, 1].std()\n",
    "            eccentricity = np.sqrt(1 - (axes[1] / axes[0])**2)\n",
    "            circumference = calculate_ellipse_circumference(axes)\n",
    "            area = calculate_ellipse_area(axes)\n",
    "\n",
    "            temperatures_points = X[points[:, 0], points[:, 1]]\n",
    "            median_temp_points = np.median(temperatures_points)\n",
    "            median_temp_remaining_points = np.median(temperatures_remaining)\n",
    "            difference_in_medians = median_temp_points - median_temp_remaining_points\n",
    "\n",
    "            cnt_str = contour_to_string(contour)\n",
    "\n",
    "            neighborhood_features.append({\n",
    "                'img_path': image_path,\n",
    "                'img_name': img_name,\n",
    "                'cx': cx,\n",
    "                'cy': cy,\n",
    "                'Major Axes': axes[0],\n",
    "                'Minor Axes': axes[1],\n",
    "                'Std PCA 1': std_pca_component_1,\n",
    "                'Std PCA 2': std_pca_component_2,\n",
    "                'Eccentricity': eccentricity,\n",
    "                'Circumference': circumference,\n",
    "                'Area': area,\n",
    "                'Median Difference': difference_in_medians,\n",
    "                'Max Difference': max_temp_diff,\n",
    "                'Min Difference': min_temp_diff,\n",
    "                'Remaining Temp Range': remaining_temp_range,\n",
    "                'Ellipse Temp Range': ellipse_temp_range\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            print(f\"Too few points to fit ellipse for image: {image_path}\")\n",
    "\n",
    "    df = pd.DataFrame(neighborhood_features)\n",
    "    return df\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "# Run the process and generate output CSV\n",
    "df = main_process(mapping_csv_file)\n",
    "\n",
    "# Add segment index column\n",
    "df.insert(0, 'idx', range(len(df)))\n",
    "\n",
    "# Save to CSV\n",
    "csv_name = 'image_features_elipse.csv'\n",
    "features_df = os.path.join(RESULT_FEATURES, csv_name)\n",
    "df.to_csv(features_df, sep=';', index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time [min]: {(end_time - start_time)/60:.2f}\")\n",
    "\n",
    "print(f\"Saved to: {RESULT_FEATURES}\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbf84f-1f15-46e3-a365-843c2109ed8e",
   "metadata": {},
   "source": [
    "### 6. Feature Mapping to Structured Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea05073a-c9a4-4d05-b053-4ec0675d0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = RESULT_FEATURES + 'image_features_elipse.csv'\n",
    "feature_mapping = RESULT_FEATURES + 'feature_mapping.txt'\n",
    "\n",
    "# Load activation feature arrays\n",
    "activations_layer_1 = np.load(RESULT_FEATURES + 'activations_layer_1_cutouts.npy')\n",
    "activations_layer_2 = np.load(RESULT_FEATURES + 'activations_layer_2_cutouts.npy')\n",
    "activations_layer_3 = np.load(RESULT_FEATURES + 'activations_layer_3_cutouts.npy')\n",
    "activations_layer_4 = np.load(RESULT_FEATURES + 'activations_layer_4_cutouts.npy')\n",
    "\n",
    "# Generate descriptive names for CNN activation features\n",
    "def generate_filter_names():\n",
    "    filter_names = []\n",
    "    filters_per_layer = {\n",
    "        1: activations_layer_1.shape[-1],\n",
    "        2: activations_layer_2.shape[-1],\n",
    "        3: activations_layer_3.shape[-1],\n",
    "        4: activations_layer_4.shape[-1]\n",
    "    }\n",
    "    for layer in range(1, 5):\n",
    "        num_filters = filters_per_layer[layer]\n",
    "        for filter_idx in range(num_filters):\n",
    "            filter_names.append(f\"Activation {layer} filter {filter_idx}\")\n",
    "    return filter_names\n",
    "\n",
    "# Generate names for CNN features\n",
    "npy_feature_names = generate_filter_names()\n",
    "\n",
    "# Load CSV feature file\n",
    "csv_data = pd.read_csv(csv_file_path, sep=';')\n",
    "\n",
    "# Extract all handcrafted (non-CNN) feature names from column index 5 onward\n",
    "csv_feature_names = csv_data.columns[5:].tolist()\n",
    "\n",
    "# Combine CNN and handcrafted feature names\n",
    "all_feature_names = npy_feature_names + csv_feature_names\n",
    "\n",
    "# Display feature names for verification\n",
    "print(\"CSV feature names:\")\n",
    "print(', '.join(f\"'{name}'\" for name in csv_feature_names))\n",
    "\n",
    "print(\"\\nTotal features (CNN + CSV):\", len(all_feature_names))\n",
    "\n",
    "# Save all feature names to a text file\n",
    "with open(feature_mapping, 'w') as f:\n",
    "    for feature_name in all_feature_names:\n",
    "        f.write(f\"{feature_name}\\n\")\n",
    "\n",
    "print(f\"\\nFeature mapping saved to {RESULT_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f593f0-efd5-4b7d-91f9-9f7c4e9c3538",
   "metadata": {},
   "source": [
    "### 7. Visualize and Label Segments (Dataset/Class Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed89114-15a2-4b99-8a45-5b3581800b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.patches import Rectangle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "features_csv_path = os.path.join(RESULT_FEATURES, \"image_features_elipse.csv\")\n",
    "\n",
    "# Window size for drawing rectangles around detected segments\n",
    "window_size = 30\n",
    "\n",
    "# Load features DataFrame with 'idx' column\n",
    "df = pd.read_csv(features_csv_path, sep=';')\n",
    "\n",
    "# Function to visualize segments on the original image\n",
    "def visualize_segments(img_name, central_points, idx_labels):\n",
    "    img_path = os.path.join(IMAGE_PATH, img_name)\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image not found: {img_path}\")\n",
    "        return\n",
    "    \n",
    "    original_image = rxr.open_rasterio(img_path).squeeze()\n",
    "    original_image_np = original_image.values\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(original_image_np, cmap='magma')\n",
    "\n",
    "    for (cx, cy), idx in zip(central_points, idx_labels):\n",
    "        rect = Rectangle((cx - window_size // 2, cy - window_size // 2), \n",
    "                         window_size, window_size, linewidth=1, \n",
    "                         edgecolor='red', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.annotate(f\"{idx}\", (cx - window_size // 2 + 2, cy - window_size // 2 - 1), \n",
    "                     color='white', weight='bold', fontsize=6, bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"black\", edgecolor=\"none\", alpha=0.4))\n",
    "\n",
    "    plt.title(f\"Segments on image: {os.path.basename(img_name)}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Group data by image and visualize segments for each image\n",
    "for img_name, group in df.groupby('img_name'):\n",
    "    central_points = list(zip(group['cx'], group['cy']))\n",
    "    idx_labels = group['idx'].tolist()\n",
    "    \n",
    "    visualize_segments(img_name, central_points, idx_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
